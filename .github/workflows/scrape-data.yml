name: Scrape new data
on:
  repository_dispatch:
    types: rescrape
  schedule:
    - cron:  '0 11 * * *'

jobs:
  scrape-courses-and-prerequisites:
    name: Scrape courses and prerequisites
    runs-on: ubuntu-latest
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v2
        with:
          path: 'scraper'
          repository: 'quacs/scraper'

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install pip requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt
          ls

      - name: Populate env
        run: printf "RIN=${{ secrets.RIN }}\nPASSWORD=${{ secrets.PASSWORD }}\nCURRENT_TERM=${{ secrets.CURRENT_TERM }}" > scraper/sis_scraper/.env

      - name: Scrape courses
        run: python3 scraper/sis_scraper/main.py

      - name: Scrape prerequisites
        run: |
          cp courses.json scraper/prerequisites_scraper
          python3 scraper/prerequisites_scraper/main.py

      - name: Upload data
        uses: actions/upload-artifact@v2
        with:
          name: courses
          path: |
            courses.json
            mod.rs
            prerequisites.json

  scrape-degree-requirements:
    name: Scrape degree requirements
    runs-on: selenium/standalone-firefox
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v2
        with:
          path: 'degree-planner'
          repository: 'quacs/degree-planner'

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install pip requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r degree-planner/requirements.txt
          ls

      - name: Populate env
        run: printf "RIN=${{ secrets.RIN }}\nPASSWORD=${{ secrets.PASSWORD }}" > degree-planner/.env

      - name: Scrape courses
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
        run: |
            cd degree-planner
            python3 scraper.py refresh_data
            mkdir degree_requirements
            mv *.json degree_requirements

      - name: Upload data
        uses: actions/upload-artifact@v2
        with:
          name: degree_requirements
          path: degree_requirements


  scrape-faculty:
    name: Scrape faculty
    runs-on: ubuntu-latest
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v2
        with:
          path: 'scraper'
          repository: 'quacs/scraper'

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install pip requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt
          ls

      - name: Scrape faculty
        run: python3 scraper/faculty_directory_scraper/main.py

      - name: Upload data
        uses: actions/upload-artifact@v2
        with:
          name: faculty
          path: faculty.json

  scrape-catalog:
    name: Scrape catalog
    runs-on: ubuntu-latest
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v2
        with:
          path: 'scraper'
          repository: 'quacs/scraper'

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install pip requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt
          ls

      - name: Scrape catalog
        run: python3 scraper/catalog_scraper/main.py

      - name: Upload data
        uses: actions/upload-artifact@v2
        with:
          name: catalog
          path: catalog.json

  commit-data:
    name: Commit changes
    continue-on-error: true
    runs-on: ubuntu-latest
    needs: [scrape-courses-and-prerequisites, scrape-faculty, scrape-catalog, scrape-degree-requirements]
    steps:
      - name: Checkout data
        uses: actions/checkout@v2
        with:
          path: 'data'
          repository: 'quacs/quacs-data'
          clean: true

      - name: Get scraped data
        uses: actions/download-artifact@v2

      - name: Generate meta json file
        run: echo {\"last_updated\":\"$(date --iso-8601=seconds -u)\"} > data/meta.json

      - name: Commit new data
        run: |
          cp courses/courses.json courses/mod.rs data
          cp courses/prerequisites.json data
          cp faculty/faculty.json data
          cp catalog/catalog.json data
          cp degree_requirements/ data

          cd data
          git config user.name "QuACS" && git config user.email "github@quacs.org"

          git add courses.json mod.rs
          git add prerequisites.json
          git add faculty.json
          git add catalog.json
          git add degree_requirements/
          git add meta.json

          git commit -m "$(date -u)"
          git push --force

      - name: Deploy updated website
        if: ${{ success() }}
        run: |
          cd data
          curl -H "Accept: application/vnd.github.everest-preview+json" \
              -H "Authorization: token ${{ secrets.GITHUBTOKEN }}" \
              --request POST \
              --data '{"event_type": "deploy"}' \
              https://api.github.com/repos/quacs/quacs/dispatches
